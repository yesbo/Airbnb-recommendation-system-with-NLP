{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using XgBoost for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_Data = pd.read_csv(\"C:/Users/Kevin Zhang/Documents/GitHub/Group20-Project/Doc/train.csv\")\n",
    "print(Train_Data.shape)\n",
    "Test_Data = pd.read_csv(\"C:/Users/Kevin Zhang/Documents/GitHub/Group20-Project/Doc/test.csv\")\n",
    "print(Test_Data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_Y = Train_Data.pop('review_scores_rating')\n",
    "print(Train_Y.shape)\n",
    "Train_X = Train_Data\n",
    "print(Train_X.shape)\n",
    "Test_Y = Test_Data.pop('review_scores_rating')\n",
    "print(Test_Y.shape)\n",
    "Test_X = Test_Data\n",
    "print(Test_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Train_X.columns)\n",
    "len(Train_X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_Data_ID = pd.DataFrame(data =Train_X['id'])\n",
    "All_Data_ID = All_Data_ID.append(pd.DataFrame(data = Test_X['id']), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_X.drop(['Unnamed: 0', 'id'], axis = 1, inplace = True)\n",
    "print(Train_X.shape)\n",
    "Test_X.drop(['Unnamed: 0', 'id'], axis = 1, inplace = True)\n",
    "print(Test_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XgBoost_Train = xgb.DMatrix(data = Train_X, label = Train_Y)\n",
    "XgBoost_Test = xgb.DMatrix(data = Test_X, label = Test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection of num_boost_round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params = {\"objective\":\"reg:linear\",'colsample_bytree': 1,'learning_rate': 0.03,'max_depth': 6, 'alpha': 0, 'gamma': 0,\n",
    "          'min_child_weight ': 1,'subsample': 1, 'lambda': 0}\n",
    "\n",
    "cv_results = xgb.cv(dtrain=XgBoost_Train, params=params, nfold=5, num_boost_round=500, \n",
    "                    metrics=\"rmse\", as_pandas=True, early_stopping_rounds=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Min_MAE_Index = cv_results['test-rmse-mean'].idxmin()\n",
    "print(cv_results.iloc[cv_results['test-rmse-mean'].idxmin()][2])\n",
    "print(Min_MAE_Index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection of Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_vector = [0.01, 0.03, 0.05, 0.07, 0.1, 0.2, 0.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMAE_learning_rate = []\n",
    "for i in range(len(learning_rate_vector)):\n",
    "    learning_rate_current = learning_rate_vector[i]\n",
    "    RMAEj = []\n",
    "    for j in range(1,11):\n",
    "        XgBoost_Fit = xgb.XGBRegressor(objective ='reg:linear', colsample_bytree = 1, learning_rate = learning_rate_current,\n",
    "                                       max_depth = 6, alpha = 0, n_estimators = Min_MAE_Index, gamma = 0, min_child_weight = 1,\n",
    "                                       subsample = 1, reg_lambda = 0)\n",
    "        X_Train, X_Validation, Y_Train, Y_Validation = train_test_split(Train_X, Train_Y, test_size=0.1)\n",
    "        XgBoost_Fit.fit(X_Train,Y_Train)\n",
    "        Preds = XgBoost_Fit.predict(X_Validation)\n",
    "        RMAEj.append(np.sqrt(mean_squared_error(Y_Validation, Preds)))\n",
    "    RMAE_learning_rate.append(np.mean(RMAEj))\n",
    "    print(\"RMSE: %f\" % (np.mean(RMAEj)))\n",
    "Optimal_Learning_Rate = learning_rate_vector[RMAE_learning_rate.index(min(RMAE_learning_rate))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Optimal_Learning_Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection of Max Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Max_Depth_Vector = range(1,11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMAE_Max_Depth = []\n",
    "for i in range(len(Max_Depth_Vector)):\n",
    "    Max_Depth_Current = Max_Depth_Vector[i]\n",
    "    RMAEj = []\n",
    "    for j in range(1,11):\n",
    "        XgBoost_Fit = xgb.XGBRegressor(objective ='reg:linear', colsample_bytree = 1, learning_rate = Optimal_Learning_Rate,\n",
    "                                       max_depth = Max_Depth_Current, alpha = 0, n_estimators = Min_MAE_Index, gamma = 0, min_child_weight = 1,\n",
    "                                       subsample = 1, reg_lambda = 0)\n",
    "        X_Train, X_Validation, Y_Train, Y_Validation = train_test_split(Train_X, Train_Y, test_size=0.1)\n",
    "        XgBoost_Fit.fit(X_Train,Y_Train)\n",
    "        Preds = XgBoost_Fit.predict(X_Validation)\n",
    "        RMAEj.append(np.sqrt(mean_squared_error(Y_Validation, Preds)))\n",
    "    RMAE_Max_Depth.append(np.mean(RMAEj))\n",
    "    print(\"RMSE: %f\" % (np.mean(RMAEj)))\n",
    "Optimal_Max_Depth = Max_Depth_Vector[RMAE_Max_Depth.index(min(RMAE_Max_Depth))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Optimal_Max_Depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection of min_child_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_child_weight_Vector = range(1,11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMAE_min_child_weight = []\n",
    "for i in range(len(min_child_weight_Vector)):\n",
    "    min_child_weight_Current = min_child_weight_Vector[i]\n",
    "    RMAEj = []\n",
    "    for j in range(1,11):\n",
    "        XgBoost_Fit = xgb.XGBRegressor(objective ='reg:linear', colsample_bytree = 1, learning_rate = Optimal_Learning_Rate,\n",
    "                                   max_depth = Optimal_Max_Depth, alpha = 0, n_estimators = Min_MAE_Index, \n",
    "                                   min_child_weight = min_child_weight_Current, gamma = 0, subsample = 1, reg_lambda = 0)\n",
    "        X_Train, X_Validation, Y_Train, Y_Validation = train_test_split(Train_X, Train_Y, test_size=0.1)\n",
    "        XgBoost_Fit.fit(X_Train,Y_Train)\n",
    "        Preds = XgBoost_Fit.predict(X_Validation)\n",
    "        RMAEj.append(np.sqrt(mean_squared_error(Y_Validation, Preds)))\n",
    "    RMAE_min_child_weight.append(np.mean(RMAEj))\n",
    "    print(\"RMSE: %f\" % (np.mean(RMAEj)))\n",
    "Optimal_min_child_weight = min_child_weight_Vector[RMAE_min_child_weight.index(min(RMAE_min_child_weight))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Optimal_min_child_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection of Gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_vector = [i/10.0 for i in range(0,7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMAE_gamma = []\n",
    "for i in range(len(gamma_vector)):\n",
    "    gamma_Current = gamma_vector[i]\n",
    "    RMAEj = []\n",
    "    for j in range(1,11):\n",
    "        XgBoost_Fit = xgb.XGBRegressor(objective ='reg:linear', colsample_bytree = 1, learning_rate = Optimal_Learning_Rate,\n",
    "                                       max_depth = Optimal_Max_Depth, alpha = 0, n_estimators = Min_MAE_Index, \n",
    "                                       min_child_weight = Optimal_min_child_weight, gamma = gamma_Current, subsample = 1, reg_lambda = 0)\n",
    "        X_Train, X_Validation, Y_Train, Y_Validation = train_test_split(Train_X, Train_Y, test_size=0.1)\n",
    "        XgBoost_Fit.fit(X_Train,Y_Train)\n",
    "        Preds = XgBoost_Fit.predict(X_Validation)\n",
    "        RMAEj.append(np.sqrt(mean_squared_error(Y_Validation, Preds)))\n",
    "    RMAE_gamma.append(np.mean(RMAEj))\n",
    "    print(\"RMSE: %f\" % (np.mean(RMAEj)))\n",
    "Optimal_gamma = gamma_vector[RMAE_gamma.index(min(RMAE_gamma))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Optimal_gamma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection of subsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsample_vector = [i/10.0 for i in range(5,11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMAE_subsample = []\n",
    "for i in range(len(subsample_vector)):\n",
    "    subsample_Current = subsample_vector[i]\n",
    "    RMAEj = []\n",
    "    for j in range(1,11):\n",
    "        XgBoost_Fit = xgb.XGBRegressor(objective ='reg:linear', colsample_bytree = 1, learning_rate = Optimal_Learning_Rate,\n",
    "                                       max_depth = Optimal_Max_Depth, alpha = 0, n_estimators = Min_MAE_Index, \n",
    "                                       min_child_weight = Optimal_min_child_weight, gamma = Optimal_gamma, subsample = subsample_Current,\n",
    "                                       reg_lambda = 0)\n",
    "        X_Train, X_Validation, Y_Train, Y_Validation = train_test_split(Train_X, Train_Y, test_size=0.1)\n",
    "        XgBoost_Fit.fit(X_Train,Y_Train)\n",
    "        Preds = XgBoost_Fit.predict(X_Validation)\n",
    "        RMAEj.append(np.sqrt(mean_squared_error(Y_Validation, Preds)))\n",
    "    RMAE_subsample.append(np.mean(RMAEj))\n",
    "    print(\"RMSE: %f\" % (np.mean(RMAEj)))\n",
    "Optimal_subsample = subsample_vector[RMAE_subsample.index(min(RMAE_subsample))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Optimal_subsample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection of colsample_bytree¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colsample_bytree_vector = [i/10.0 for i in range(5,11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMAE_colsample_bytree = []\n",
    "for i in range(len(colsample_bytree_vector)):\n",
    "    colsample_bytree_Current = colsample_bytree_vector[i]\n",
    "    RMAEj = []\n",
    "    for j in range(1,11):\n",
    "        XgBoost_Fit = xgb.XGBRegressor(objective ='reg:linear', colsample_bytree = colsample_bytree_Current, \n",
    "                                       learning_rate = Optimal_Learning_Rate,\n",
    "                                       max_depth = Optimal_Max_Depth, alpha = 0, n_estimators = Min_MAE_Index, \n",
    "                                       min_child_weight = Optimal_min_child_weight, gamma = Optimal_gamma, subsample = Optimal_subsample,\n",
    "                                       reg_lambda = 0)\n",
    "        X_Train, X_Validation, Y_Train, Y_Validation = train_test_split(Train_X, Train_Y, test_size=0.1)\n",
    "        XgBoost_Fit.fit(X_Train,Y_Train)\n",
    "        Preds = XgBoost_Fit.predict(X_Validation)\n",
    "        RMAEj.append(np.sqrt(mean_squared_error(Y_Validation, Preds)))\n",
    "    RMAE_colsample_bytree.append(np.mean(RMAEj))\n",
    "    print(\"RMSE: %f\" % (np.mean(RMAEj)))\n",
    "Optimal_colsample_bytree = colsample_bytree_vector[RMAE_colsample_bytree.index(min(RMAE_colsample_bytree))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Optimal_colsample_bytree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection of alpha¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_vector = [0, 0.001, 0.005, 0.01, 0.05, 0.5, 1, 3, 5, 10, 50, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMAE_alpha = []\n",
    "for i in range(len(alpha_vector)):\n",
    "    alpha_Current = alpha_vector[i]\n",
    "    RMAEj = []\n",
    "    for j in range(1,11):\n",
    "        XgBoost_Fit = xgb.XGBRegressor(objective ='reg:linear', colsample_bytree = Optimal_colsample_bytree, \n",
    "                                       learning_rate = Optimal_Learning_Rate,\n",
    "                                       max_depth = Optimal_Max_Depth, alpha = alpha_Current, n_estimators = Min_MAE_Index, \n",
    "                                       min_child_weight = Optimal_min_child_weight, gamma = Optimal_gamma, subsample = Optimal_subsample,\n",
    "                                       reg_lambda = 0)\n",
    "        X_Train, X_Validation, Y_Train, Y_Validation = train_test_split(Train_X, Train_Y, test_size=0.1)\n",
    "        XgBoost_Fit.fit(X_Train,Y_Train)\n",
    "        Preds = XgBoost_Fit.predict(X_Validation)\n",
    "        RMAEj.append(np.sqrt(mean_squared_error(Y_Validation, Preds)))\n",
    "    RMAE_alpha.append(np.mean(RMAEj))\n",
    "    print(\"RMSE: %f\" % (np.mean(RMAEj)))\n",
    "Optimal_alpha = alpha_vector[RMAE_alpha.index(min(RMAE_alpha))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Optimal_alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trained XgBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "XgBoost_Fit = xgb.XGBRegressor(objective ='reg:linear', colsample_bytree = Optimal_colsample_bytree, \n",
    "                               learning_rate = Optimal_Learning_Rate,\n",
    "                               max_depth = Optimal_Max_Depth, alpha = Optimal_alpha, n_estimators = Min_MAE_Index, \n",
    "                               min_child_weight = Optimal_min_child_weight, gamma = Optimal_gamma, subsample = Optimal_subsample,\n",
    "                               reg_lambda = 0)\n",
    "XgBoost_Fit.fit(Train_X,Train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Preds = XgBoost_Fit.predict(Test_X)\n",
    "elapsed_time = time.time() - start_time\n",
    "print(elapsed_time)\n",
    "print(\"RMSE: %f\" % (np.sqrt(mean_squared_error(Preds, Test_Y))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(Preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction for Whole Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_Data = Train_X.append(pd.DataFrame(data = Test_X), ignore_index=True)\n",
    "Preds = XgBoost_Fit.predict(All_Data)\n",
    "All_Data_Pred = pd.concat([All_Data_ID, pd.DataFrame(Preds,columns=['Prediction'])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_Data_Pred.to_csv('All_Data_Pred.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.plot_importance(XgBoost_Fit, max_num_features = 10)\n",
    "plt.rcParams['figure.figsize'] = [19, 10]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why MAE?\n",
    "\n",
    "https://medium.com/human-in-a-machine-world/mae-and-rmse-which-metric-is-better-e60ac3bde13d\n",
    "\n",
    "XgBoost\n",
    "\n",
    "https://www.datacamp.com/community/tutorials/xgboost-in-python\n",
    "\n",
    "Tuning Parameter for XgBoost\n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/\n",
    "\n",
    "XgBoost Website\n",
    "\n",
    "https://xgboost.readthedocs.io/en/latest/parameter.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
